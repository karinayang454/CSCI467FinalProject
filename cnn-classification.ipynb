{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7598969,"sourceType":"datasetVersion","datasetId":4423404}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, datasets\nfrom sklearn.model_selection import train_test_split\nimport os\nfrom PIL import Image\n\nclass ImageClassifier(nn.Module):\n    def __init__(self):\n        super(ImageClassifier, self).__init__()\n        # Convolutional layers\n        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        # Max pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n        # Fully connected layers with dropout\n        self.fc1 = nn.Linear(32 * 28 * 28, 512)\n        self.fc2 = nn.Linear(512, 128)\n        self.fc3 = nn.Linear(128, 1)  # Output is a single value (real or generated)\n        # Dropout layer for regularization\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        # Apply convolutional and pooling layers\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        # Flatten the output for the fully connected layers\n        x = torch.flatten(x, 1)\n        # Apply fully connected layers with dropout\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = torch.sigmoid(self.fc3(x))  # Sigmoid activation for binary classification\n        return x\n\n# Custom dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_files = os.listdir(root_dir)\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir, self.image_files[idx])\n        image = Image.open(img_name).convert(\"RGB\")  # Convert to RGB in case of grayscale\n        if self.transform:\n            image = self.transform(image)\n        label = 0 if \"RealArt\" in self.root_dir else 1  # RealArt: 0, AiArtData: 1\n        return image, label\n\n# Data transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize to 224x224\n    transforms.RandomHorizontalFlip(),  # Augmentation: Random horizontal flip\n    transforms.RandomRotation(15),       # Augmentation: Random rotation by 15 degrees\n    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),  # Adjust brightness, contrast, saturation, and hue\n    transforms.ToTensor(),\n])\n# Load datasets\nreal_dataset = CustomDataset('/kaggle/input/ai-generated-images-vs-real-images/RealArt/RealArt/', transform=transform)\ngenerated_dataset = CustomDataset('/kaggle/input/ai-generated-images-vs-real-images/AiArtData/AiArtData/', transform=transform)\n\n# Split datasets into train, validation, and test\nreal_train, real_val_test = train_test_split(real_dataset, test_size=0.2, random_state=45)\ngen_train, gen_val_test = train_test_split(generated_dataset, test_size=0.2, random_state=45)\n\nreal_val, real_test = train_test_split(real_val_test, test_size=0.5, random_state=45)\ngen_val, gen_test = train_test_split(gen_val_test, test_size=0.5, random_state=42)\n\n# Combine datasets for training, validation, and test\ntrain_dataset = torch.utils.data.ConcatDataset([real_train, gen_train])\nval_dataset = torch.utils.data.ConcatDataset([real_val, gen_val])\ntest_dataset = torch.utils.data.ConcatDataset([real_test, gen_test])\n\n# Create dataloaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32)\ntest_loader = DataLoader(test_dataset, batch_size=32)\n\n# Initialize model, loss function, and optimizer\nmodel = ImageClassifier()\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.0002)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-04T19:10:34.507752Z","iopub.execute_input":"2024-05-04T19:10:34.508140Z","iopub.status.idle":"2024-05-04T19:11:12.597191Z","shell.execute_reply.started":"2024-05-04T19:10:34.508113Z","shell.execute_reply":"2024-05-04T19:11:12.596289Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport torch\nimport torch.optim as optim\n\nnum_epochs = 10\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nbest_val_loss = float('inf')  # Initialize with a very large number\nbest_model_path = \"best_model.pth\"  # Path to save the best model\n\nstart_time = time.time()\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    # Validation\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n            outputs = model(images)\n            val_loss += criterion(outputs, labels).item()\n\n    # Calculate average losses\n    avg_train_loss = running_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n\n    # Print epoch statistics\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n\n    # Save the model if validation loss has improved\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        torch.save(model.state_dict(), best_model_path)\n        print(f\"  Saved best model with val loss: {best_val_loss:.4f}\")\n\nend_time = time.time()\nelapsed_time = end_time - start_time\nprint(f\"Training complete. Elapsed time: {elapsed_time:.2f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T19:11:12.598993Z","iopub.execute_input":"2024-05-04T19:11:12.599259Z","iopub.status.idle":"2024-05-04T19:11:19.751062Z","shell.execute_reply.started":"2024-05-04T19:11:12.599236Z","shell.execute_reply":"2024-05-04T19:11:19.750133Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/10, Train Loss: 0.6971, Val Loss: 0.6310\n  Saved best model with val loss: 0.6310\nEpoch 2/10, Train Loss: 0.6794, Val Loss: 0.6119\n  Saved best model with val loss: 0.6119\nEpoch 3/10, Train Loss: 0.6630, Val Loss: 0.6217\nEpoch 4/10, Train Loss: 0.6588, Val Loss: 0.5963\n  Saved best model with val loss: 0.5963\nEpoch 5/10, Train Loss: 0.6465, Val Loss: 0.5774\n  Saved best model with val loss: 0.5774\nEpoch 6/10, Train Loss: 0.6323, Val Loss: 0.6261\nEpoch 7/10, Train Loss: 0.6261, Val Loss: 0.5581\n  Saved best model with val loss: 0.5581\nEpoch 8/10, Train Loss: 0.5786, Val Loss: 0.5793\nEpoch 9/10, Train Loss: 0.5630, Val Loss: 0.5845\nEpoch 10/10, Train Loss: 0.5004, Val Loss: 0.6592\nTraining complete. Elapsed time: 7.13 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report\nmodel.load_state_dict(torch.load(best_model_path, map_location=device))\nmodel.eval()\n\npredicted_labels = []\ntrue_labels = []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n        outputs = model(images)\n        predicted = (torch.sigmoid(outputs) > 0.5).float()\n        predicted_labels.extend(predicted.cpu().numpy().flatten())\n        true_labels.extend(labels.cpu().numpy().flatten())\n\npredicted_labels = np.array(predicted_labels).astype(int)\ntrue_labels = np.array(true_labels).astype(int)\n\n# Compute and print classification report\nreport = classification_report(true_labels, predicted_labels, target_names=[\"Real\", \"Generated\"], digits=4)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T19:11:19.752672Z","iopub.execute_input":"2024-05-04T19:11:19.753270Z","iopub.status.idle":"2024-05-04T19:11:19.833470Z","shell.execute_reply.started":"2024-05-04T19:11:19.753222Z","shell.execute_reply":"2024-05-04T19:11:19.832442Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Real     0.0000    0.0000    0.0000        44\n   Generated     0.5510    1.0000    0.7105        54\n\n    accuracy                         0.5510        98\n   macro avg     0.2755    0.5000    0.3553        98\nweighted avg     0.3036    0.5510    0.3915        98\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]}]}